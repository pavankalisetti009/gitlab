# frozen_string_literal: true

module Ai
  class UsageEvent < ApplicationRecord
    include EachBatch
    include ClickHouseModel
    include PartitionedTable
    include Analytics::HasWriteBuffer

    self.table_name = "ai_usage_events"
    self.clickhouse_table_name = "ai_usage_events"

    partitioned_by :timestamp, strategy: :monthly, retain_for: 3.months
    self.primary_key = :id

    populate_sharding_key(:organization_id) { Gitlab::Current::Organization.new(user: user).organization&.id }

    self.write_buffer_options = { class: Analytics::LegacyAiUsageDatabaseWriteBuffer }

    belongs_to :user
    belongs_to :organization, class_name: 'Organizations::Organization'
    belongs_to :namespace, optional: true
    attribute :timestamp, :datetime, default: -> { DateTime.current }

    enum :event, Gitlab::Tracking::AiTracking.registered_events

    validates :timestamp, :user_id, :organization_id, presence: true
    validates :namespace, presence: true, if: :namespace_id?
    validates :extras, json_schema: { filename: "ai_usage_event_extras", size_limit: 16.kilobytes }
    validate :validate_recent_timestamp, on: :create
    validate :validate_event_status, on: :create

    before_validation :floor_timestamp

    scope :with_namespace, -> { includes(:namespace) }
    scope :sort_by_timestamp_id, ->(dir: :desc) { order(timestamp: dir, id: dir) }

    scope :in_timeframe, ->(range) { where(timestamp: range) }
    scope :with_events, ->(event_names) { where(event: event_names) }
    scope :with_users, ->(users) { where(user: users) }
    scope :for_namespace_hierarchy, ->(namespace) do
      base_usage_events = order_values.any? ? self : sort_by_timestamp_id
      related_namespaces = namespace.self_and_descendant_ids(skope: Namespace)
      namespace_mapping_scope = ->(namespace_ids) do
        ::Ai::UsageEvent.where(arel_table[:namespace_id].eq(namespace_ids))
      end
      finder_query = ->(_timestamp_expression, id_expression) do
        ::Ai::UsageEvent.where(arel_table[:id].eq(id_expression))
      end

      Gitlab::Pagination::Keyset::InOperatorOptimization::QueryBuilder.new(
        scope: base_usage_events,
        array_scope: related_namespaces,
        array_mapping_scope: namespace_mapping_scope,
        finder_query: finder_query
      ).execute
    end

    def store_to_pg
      return false unless valid?

      attrs = attributes_for_database.compact
      attrs['extras'] = attributes['extras'] # preserve JSON type for extras

      self.class.write_buffer.add(attrs)
    end

    def to_clickhouse_csv_row
      {
        event: self.class.events[event],
        # we round to 3 digits here to avoid floating number inconsistencies.
        # until https://gitlab.com/gitlab-org/gitlab/-/issues/527129
        # is resolved
        timestamp: Time.zone.parse(timestamp.as_json).to_f.round(3),
        user_id: user&.id,
        namespace_path: namespace&.traversal_path,
        extras: extras.to_json
      }
    end

    private

    def floor_timestamp
      # we floor to 3 digits here to match current JSON rounding used in Write Buffers.
      # That creates consistency between PG and CH until https://gitlab.com/gitlab-org/gitlab/-/issues/527129
      # is resolved
      self.timestamp = timestamp&.floor(3)
    end

    def validate_recent_timestamp
      return unless timestamp && timestamp < self.class.partitioning_strategy.retain_for.ago

      errors.add(:timestamp, _('must be 3 months old at the most'))
    end

    def validate_event_status
      return unless Gitlab::Tracking::AiTracking.deprecated_event?(event)

      errors.add(:event, _('is read-only'))
    end
  end
end
