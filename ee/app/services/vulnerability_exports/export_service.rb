# frozen_string_literal: true

require 'async'
require 'async/semaphore'

module VulnerabilityExports
  class ExportService
    include ::Gitlab::ExclusiveLeaseHelpers

    LEASE_TTL = 1.hour
    LEASE_NAMESPACE = "vulnerability_exports_export"
    EXPORTERS = {
      'csv' => VulnerabilityExports::Exporters::CsvService
    }.freeze
    BATCH_SIZE = 100

    # This constant determines the number of records to be handled per segmented export.
    VULNERABILITY_READS_PARTIAL_FILE_BATCH_SIZE = 25_000
    SEGMENTED_EXPORT_WORKERS = 10
    NUMBER_OF_CONCURRENT_TASKS = 5

    def self.export(vulnerability_export)
      new(vulnerability_export).export
    end

    def initialize(vulnerability_export)
      self.vulnerability_export = vulnerability_export
    end

    def export
      in_lock(lease_key, ttl: LEASE_TTL) do
        break unless vulnerability_export.created?

        enqueue_segmented_export
      end
    end

    def export_segment(part)
      first_record = Vulnerabilities::Read.find(part.start_id)
      last_record = Vulnerabilities::Read.find(part.end_id)

      iterator = default_iterator do |scope|
        if exportable.is_a?(Group)
          scope.in_parent_group_after_and_including(first_record).in_parent_group_before_and_including(last_record)
        else
          scope.by_vulnerabilities(first_record.vulnerability_id..last_record.vulnerability_id)
        end
      end

      enumerator = vulnerabilities_enumerator(iterator)
      exporter = exporter(enumerator)

      @serialization_duration_s = Benchmark.realtime do
        exporter.generate { |f| part.file = f }
      end

      part.file.filename = segment_filename(part.start_id, part.end_id)

      @file_size_bytes = part.file.size
      @upload_duration_s = Benchmark.realtime { part.save! }

      log_export_results('Export part uploaded')
    rescue StandardError => exception
      log_export_results('Export part generation failed', exception: exception)
      vulnerability_export.failed!
      vulnerability_export.schedule_export_deletion
      raise
    end

    def finalise_segmented_export
      tempfile = Tempfile.new

      # The header can be nil for formats like JSONL if we add them later.
      tempfile.puts(export_header) if export_header

      @download_duration_s = Benchmark.realtime { download_export_parts(tempfile) }

      @file_size_bytes = tempfile.size

      vulnerability_export.file = tempfile
      vulnerability_export.file.filename = filename

      @upload_duration_s = Benchmark.realtime { vulnerability_export.store_file_now! }

      vulnerability_export.finish!
      vulnerability_export.send_completion_email!

      log_export_results('Export finalization completed')
    rescue StandardError => exception
      log_export_results('Export finalization failed', exception: exception)
      vulnerability_export.failed!
      raise
    ensure
      vulnerability_export.schedule_export_deletion
      tempfile.close!
    end

    private

    def download_export_parts(tempfile)
      @vulnerability_count = 0

      Async do
        semaphore = Async::Semaphore.new(NUMBER_OF_CONCURRENT_TASKS)
        write_semaphore = Async::Semaphore.new

        tasks = vulnerability_export.export_parts.map(&:file).map do |file|
          semaphore.async do
            file.open do |stream|
              stream.readline if export_header.present? # Moves the cursor to next line

              stream.each_line do |line|
                @vulnerability_count += 1
                write_semaphore.acquire do
                  # The encoding of the parts is read as ASCI-8BIT.
                  # We need to force the encoding to utf-8 to avoid a write failure due to
                  # wide-chars used in place like group names.
                  # See:
                  # https://github.com/carrierwaveuploader/carrierwave/issues/1583
                  # https://gitlab.com/gitlab-org/gitlab/-/blob/0aa846a1baa08b1f6f11b2711f8f6bf880542a46/lib/gitlab/http_io.rb
                  tempfile << line.force_encoding(Encoding::UTF_8)
                end
              end
            end
          end
        end

        tasks.each(&:wait)
      end.wait
    end

    attr_accessor :vulnerability_export

    delegate :exportable, :format, to: :vulnerability_export, private: true

    def export_header
      @export_header ||= exporter.header
    end

    def lease_key
      "#{LEASE_NAMESPACE}:#{vulnerability_export.id}"
    end

    def enqueue_segmented_export
      vulnerability_export.start!
      parts = []

      default_iterator.each_batch(of: VULNERABILITY_READS_PARTIAL_FILE_BATCH_SIZE) do |records|
        next if records.empty? # each_batch can return an empty batch

        parts << ::Vulnerabilities::Export::Part.create(
          vulnerability_export_id: vulnerability_export.id,
          start_id: records.first.id,
          end_id: records.last.id,
          organization_id: vulnerability_export.organization_id
        ).id
      end

      parts_count = parts.length
      group_size = [parts_count, SEGMENTED_EXPORT_WORKERS].min

      if group_size == 0
        return ::Gitlab::Export::SegmentedExportFinalisationWorker.perform_async(vulnerability_export.to_global_id.to_s)
      end

      segments = parts.in_groups(group_size, false)

      segments.each do |segment|
        ::Gitlab::Export::SegmentedExportWorker.perform_async(vulnerability_export.to_global_id.to_s, segment)
      end

      log_export_results('Queued segmented export', parts_count: parts_count)
    rescue StandardError => exception
      log_export_results('Failed to queue segmented export', exception: exception)
      vulnerability_export.failed!
      vulnerability_export.schedule_export_deletion
      raise
    end

    def exporter(scope = vulnerability_reads_scope)
      @exporter ||= EXPORTERS[format].new(scope)
    end

    def vulnerabilities_enumerator(iterator)
      Enumerator.new do |yielder|
        iterator.each_batch(of: BATCH_SIZE) do |records|
          records.with_export_entities.to_a.each do |vulnerability_read|
            yielder.yield(vulnerability_read)
          end
        end
      end
    end

    def default_iterator
      scope = vulnerability_reads_scope
      scope = yield scope if block_given?

      Gitlab::Pagination::Keyset::Iterator.new(
        scope: scope,
        use_union_optimization: false
      )
    end

    def vulnerability_reads_scope
      if exportable.is_a?(Group)
        exportable.vulnerability_reads.unarchived.order_traversal_ids_asc
      else
        Security::VulnerabilityReadsFinder.new(exportable).execute
                                          .order_detected_at_asc
      end
    end

    def filename
      filename_structure('_vulnerabilities_')
    end

    def segment_filename(start_id, end_id)
      filename_structure("_vulnerabilities_segment_#{start_id}_to_#{end_id}")
    end

    def filename_structure(custom_part)
      [
        exportable.full_path.parameterize,
        custom_part,
        Time.current.utc.strftime('%FT%H%M'),
        '.',
        format
      ].join
    end

    def log_export_results(message, exception: nil, **fields)
      log_context = export_context.merge(**fields)

      if exception
        log_context = log_context.merge(
          'exception.class' => exception.class.name,
          'exception.message' => exception.message,
          'exception.backtrace' => exception.backtrace
        )
      end

      ::Gitlab::AppLogger.info(message: message, **log_context)
    end

    def export_context
      fields = {
        file_size_bytes: @file_size_bytes,
        vulnerability_count: @vulnerability_count,
        serialization_duration_s: @serialization_duration_s&.round(6),
        download_duration_s: @download_duration_s&.round(6),
        upload_duration_s: @upload_duration_s&.round(6)
      }.compact

      ::Gitlab::ApplicationContext.current.merge(**fields)
    end
  end
end
